import os
import numpy as np
import tempfile, zipfile
import torch
import torch.nn as nn
import torch.nn.functional as F
try:
    import torchvision
    import torchaudio
except:
    pass

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()

        self.image_to = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=3, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.enc_0_temb_to_ch = nn.Linear(bias=True, in_features=30, out_features=64)
        self.enc_0_conv1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.enc_0_act = nn.ReLU()
        self.enc_0_conv2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_0 = nn.ReLU()
        self.enc_0_conv3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_1 = nn.ReLU()
        self.downsamplers_0 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(2,2), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(2,2))
        self.enc_1_temb_to_ch = nn.Linear(bias=True, in_features=30, out_features=128)
        self.enc_1_conv1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding='same', padding_mode='zeros', stride=(1,1))
        self.enc_1_act = nn.ReLU()
        self.enc_1_conv2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_2 = nn.ReLU()
        self.enc_1_conv3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_3 = nn.ReLU()
        self.downsamplers_1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(2,2), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(2,2))
        self.enc_2_temb_to_ch = nn.Linear(bias=True, in_features=30, out_features=256)
        self.enc_2_conv1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(3,3), out_channels=256, padding='same', padding_mode='zeros', stride=(1,1))
        self.enc_2_act = nn.ReLU()
        self.enc_2_conv2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(3,3), out_channels=256, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_4 = nn.ReLU()
        self.enc_2_conv3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(3,3), out_channels=256, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_5 = nn.ReLU()
        self.to_query = nn.Linear(bias=True, in_features=256, out_features=256)
        self.to_key = nn.Linear(bias=True, in_features=256, out_features=256)
        self.to_value = nn.Linear(bias=True, in_features=256, out_features=256)
        self.attention = nn.MultiheadAttention(add_bias_kv=False, add_zero_attn=False, batch_first=True, bias=True, embed_dim=256, kdim=256, num_heads=1, vdim=256)
        self.out_proj = nn.Linear(bias=True, in_features=256, out_features=256)
        self.upsamplers_0 = nn.ConvTranspose2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(2,2), out_channels=128, output_padding=(0,0), padding=(0,0), stride=(2,2))
        self.dec_0_temb_to_ch = nn.Linear(bias=True, in_features=30, out_features=128)
        self.dec_0_conv1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(3,3), out_channels=128, padding='same', padding_mode='zeros', stride=(1,1))
        self.dec_0_act = nn.ReLU()
        self.dec_0_conv2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_6 = nn.ReLU()
        self.dec_0_conv3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_7 = nn.ReLU()
        self.upsamplers_1 = nn.ConvTranspose2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(2,2), out_channels=64, output_padding=(0,0), padding=(0,0), stride=(2,2))
        self.dec_1_temb_to_ch = nn.Linear(bias=True, in_features=30, out_features=64)
        self.dec_1_conv1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.dec_1_act = nn.ReLU()
        self.dec_1_conv2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_8 = nn.ReLU()
        self.dec_1_conv3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding='same', padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_9 = nn.ReLU()
        self.to_image = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=3, padding='same', padding_mode='zeros', stride=(1,1))

        archive = zipfile.ZipFile('models/unet_scripted.pnnx.bin', 'r')
        self.image_to.bias = self.load_pnnx_bin_as_parameter(archive, 'image_to.bias', (64), 'float32')
        self.image_to.weight = self.load_pnnx_bin_as_parameter(archive, 'image_to.weight', (64,3,3,3), 'float32')
        self.enc_0_temb_to_ch.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.0.temb_to_ch.bias', (64), 'float32')
        self.enc_0_temb_to_ch.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.0.temb_to_ch.weight', (64,30), 'float32')
        self.enc_0_conv1.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.0.conv1.bias', (64), 'float32')
        self.enc_0_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.0.conv1.weight', (64,64,3,3), 'float32')
        self.enc_0_conv2.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.0.conv2.bias', (64), 'float32')
        self.enc_0_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.0.conv2.weight', (64,64,3,3), 'float32')
        self.enc_0_conv3.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.0.conv3.bias', (64), 'float32')
        self.enc_0_conv3.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.0.conv3.weight', (64,64,3,3), 'float32')
        self.downsamplers_0.bias = self.load_pnnx_bin_as_parameter(archive, 'downsamplers.0.bias', (128), 'float32')
        self.downsamplers_0.weight = self.load_pnnx_bin_as_parameter(archive, 'downsamplers.0.weight', (128,64,2,2), 'float32')
        self.enc_1_temb_to_ch.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.1.temb_to_ch.bias', (128), 'float32')
        self.enc_1_temb_to_ch.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.1.temb_to_ch.weight', (128,30), 'float32')
        self.enc_1_conv1.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.1.conv1.bias', (128), 'float32')
        self.enc_1_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.1.conv1.weight', (128,128,3,3), 'float32')
        self.enc_1_conv2.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.1.conv2.bias', (128), 'float32')
        self.enc_1_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.1.conv2.weight', (128,128,3,3), 'float32')
        self.enc_1_conv3.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.1.conv3.bias', (128), 'float32')
        self.enc_1_conv3.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.1.conv3.weight', (128,128,3,3), 'float32')
        self.downsamplers_1.bias = self.load_pnnx_bin_as_parameter(archive, 'downsamplers.1.bias', (256), 'float32')
        self.downsamplers_1.weight = self.load_pnnx_bin_as_parameter(archive, 'downsamplers.1.weight', (256,128,2,2), 'float32')
        self.enc_2_temb_to_ch.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.2.temb_to_ch.bias', (256), 'float32')
        self.enc_2_temb_to_ch.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.2.temb_to_ch.weight', (256,30), 'float32')
        self.enc_2_conv1.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.2.conv1.bias', (256), 'float32')
        self.enc_2_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.2.conv1.weight', (256,256,3,3), 'float32')
        self.enc_2_conv2.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.2.conv2.bias', (256), 'float32')
        self.enc_2_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.2.conv2.weight', (256,256,3,3), 'float32')
        self.enc_2_conv3.bias = self.load_pnnx_bin_as_parameter(archive, 'enc.2.conv3.bias', (256), 'float32')
        self.enc_2_conv3.weight = self.load_pnnx_bin_as_parameter(archive, 'enc.2.conv3.weight', (256,256,3,3), 'float32')
        self.to_query.bias = self.load_pnnx_bin_as_parameter(archive, 'to_query.bias', (256), 'float32')
        self.to_query.weight = self.load_pnnx_bin_as_parameter(archive, 'to_query.weight', (256,256), 'float32')
        self.to_key.bias = self.load_pnnx_bin_as_parameter(archive, 'to_key.bias', (256), 'float32')
        self.to_key.weight = self.load_pnnx_bin_as_parameter(archive, 'to_key.weight', (256,256), 'float32')
        self.to_value.bias = self.load_pnnx_bin_as_parameter(archive, 'to_value.bias', (256), 'float32')
        self.to_value.weight = self.load_pnnx_bin_as_parameter(archive, 'to_value.weight', (256,256), 'float32')
        self.attention.in_proj_bias = self.load_pnnx_bin_as_parameter(archive, 'attention.in_proj_bias', (768), 'float32')
        self.attention.in_proj_weight = self.load_pnnx_bin_as_parameter(archive, 'attention.in_proj_weight', (768,256), 'float32')
        self.attention.out_proj.bias = self.load_pnnx_bin_as_parameter(archive, 'attention.out_proj.bias', (256), 'float32')
        self.attention.out_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'attention.out_proj.weight', (256,256), 'float32')
        self.out_proj.bias = self.load_pnnx_bin_as_parameter(archive, 'out_proj.bias', (256), 'float32')
        self.out_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'out_proj.weight', (256,256), 'float32')
        self.upsamplers_0.bias = self.load_pnnx_bin_as_parameter(archive, 'upsamplers.0.bias', (128), 'float32')
        self.upsamplers_0.weight = self.load_pnnx_bin_as_parameter(archive, 'upsamplers.0.weight', (256,128,2,2), 'float32')
        self.dec_0_temb_to_ch.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.0.temb_to_ch.bias', (128), 'float32')
        self.dec_0_temb_to_ch.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.0.temb_to_ch.weight', (128,30), 'float32')
        self.dec_0_conv1.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.0.conv1.bias', (128), 'float32')
        self.dec_0_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.0.conv1.weight', (128,256,3,3), 'float32')
        self.dec_0_conv2.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.0.conv2.bias', (128), 'float32')
        self.dec_0_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.0.conv2.weight', (128,128,3,3), 'float32')
        self.dec_0_conv3.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.0.conv3.bias', (128), 'float32')
        self.dec_0_conv3.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.0.conv3.weight', (128,128,3,3), 'float32')
        self.upsamplers_1.bias = self.load_pnnx_bin_as_parameter(archive, 'upsamplers.1.bias', (64), 'float32')
        self.upsamplers_1.weight = self.load_pnnx_bin_as_parameter(archive, 'upsamplers.1.weight', (128,64,2,2), 'float32')
        self.dec_1_temb_to_ch.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.1.temb_to_ch.bias', (64), 'float32')
        self.dec_1_temb_to_ch.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.1.temb_to_ch.weight', (64,30), 'float32')
        self.dec_1_conv1.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.1.conv1.bias', (64), 'float32')
        self.dec_1_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.1.conv1.weight', (64,128,3,3), 'float32')
        self.dec_1_conv2.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.1.conv2.bias', (64), 'float32')
        self.dec_1_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.1.conv2.weight', (64,64,3,3), 'float32')
        self.dec_1_conv3.bias = self.load_pnnx_bin_as_parameter(archive, 'dec.1.conv3.bias', (64), 'float32')
        self.dec_1_conv3.weight = self.load_pnnx_bin_as_parameter(archive, 'dec.1.conv3.weight', (64,64,3,3), 'float32')
        self.to_image.bias = self.load_pnnx_bin_as_parameter(archive, 'to_image.bias', (3), 'float32')
        self.to_image.weight = self.load_pnnx_bin_as_parameter(archive, 'to_image.weight', (3,64,1,1), 'float32')
        self.pnnx_fold_div_term_1_data = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_div_term.1.data', (15,), 'float32')
        self.pnnx_fold_div_term_1_1_data = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_div_term.1_1.data', (15,), 'float32')
        archive.close()

    def load_pnnx_bin_as_parameter(self, archive, key, shape, dtype, requires_grad=True):
        return nn.Parameter(self.load_pnnx_bin_as_tensor(archive, key, shape, dtype), requires_grad)

    def load_pnnx_bin_as_tensor(self, archive, key, shape, dtype):
        fd, tmppath = tempfile.mkstemp()
        with os.fdopen(fd, 'wb') as tmpf, archive.open(key) as keyfile:
            tmpf.write(keyfile.read())
        m = np.memmap(tmppath, dtype=dtype, mode='r', shape=shape).copy()
        os.remove(tmppath)
        return torch.from_numpy(m)

    def forward(self, v_0, v_1):
        v_2 = self.pnnx_fold_div_term_1_data
        v_3 = self.pnnx_fold_div_term_1_1_data
        v_4 = v_1.unsqueeze(1)
        v_5 = v_4.to(copy=False, dtype=torch.float)
        v_6 = torch.sin((v_5 * v_2))
        v_7 = torch.cos((v_5 * v_3))
        v_8 = torch.stack((v_6, v_7), dim=-1)
        v_9 = v_8.reshape(1, 30)
        v_10 = self.image_to(v_0)
        v_11 = self.enc_0_temb_to_ch(v_9)
        v_12 = self.enc_0_conv1(v_10)
        v_13 = self.enc_0_act(v_12)
        v_14 = v_11.reshape(1, 64, 1, 1)
        v_15 = (v_13 + v_14)
        v_16 = self.enc_0_conv2(v_15)
        v_17 = self.pnnx_unique_0(v_16)
        v_18 = self.enc_0_conv3(v_17)
        v_19 = self.pnnx_unique_1(v_18)
        v_20 = (v_19 + v_10)
        v_21 = torch.clone(input=v_20)
        v_22 = self.downsamplers_0(v_20)
        v_23 = self.enc_1_temb_to_ch(v_9)
        v_24 = self.enc_1_conv1(v_22)
        v_25 = self.enc_1_act(v_24)
        v_26 = v_23.reshape(1, 128, 1, 1)
        v_27 = (v_25 + v_26)
        v_28 = self.enc_1_conv2(v_27)
        v_29 = self.pnnx_unique_2(v_28)
        v_30 = self.enc_1_conv3(v_29)
        v_31 = self.pnnx_unique_3(v_30)
        v_32 = (v_31 + v_22)
        v_33 = torch.clone(input=v_32)
        v_34 = self.downsamplers_1(v_32)
        v_35 = self.enc_2_temb_to_ch(v_9)
        v_36 = self.enc_2_conv1(v_34)
        v_37 = self.enc_2_act(v_36)
        v_38 = v_35.reshape(1, 256, 1, 1)
        v_39 = (v_37 + v_38)
        v_40 = self.enc_2_conv2(v_39)
        v_41 = self.pnnx_unique_4(v_40)
        v_42 = self.enc_2_conv3(v_41)
        v_43 = self.pnnx_unique_5(v_42)
        v_44 = (v_43 + v_34)
        v_45 = torch.flatten(input=v_44, end_dim=-1, start_dim=2)
        v_46 = v_45.permute(dims=(0,2,1))
        v_47 = self.to_query(v_46)
        v_48 = self.to_key(v_46)
        v_49 = self.to_value(v_46)
        v_50, _ = self.attention(v_47, v_48, v_49, need_weights=False)
        v_51 = self.out_proj(v_50)
        v_52 = v_51.permute(dims=(0,2,1))
        v_53 = v_52.reshape(1, 256, 8, 8)
        v_54 = (v_44 + v_53)
        v_55 = self.upsamplers_0(v_54)
        v_56 = torch.cat((v_55, v_33), dim=1)
        v_57 = self.dec_0_temb_to_ch(v_9)
        v_58 = self.dec_0_conv1(v_56)
        v_59 = self.dec_0_act(v_58)
        v_60 = v_57.reshape(1, 128, 1, 1)
        v_61 = (v_59 + v_60)
        v_62 = self.dec_0_conv2(v_61)
        v_63 = self.pnnx_unique_6(v_62)
        v_64 = self.dec_0_conv3(v_63)
        v_65 = self.pnnx_unique_7(v_64)
        v_66 = (v_65 + v_55)
        v_67 = self.upsamplers_1(v_66)
        v_68 = torch.cat((v_67, v_21), dim=1)
        v_69 = self.dec_1_temb_to_ch(v_9)
        v_70 = self.dec_1_conv1(v_68)
        v_71 = self.dec_1_act(v_70)
        v_72 = v_69.reshape(1, 64, 1, 1)
        v_73 = (v_71 + v_72)
        v_74 = self.dec_1_conv2(v_73)
        v_75 = self.pnnx_unique_8(v_74)
        v_76 = self.dec_1_conv3(v_75)
        v_77 = self.pnnx_unique_9(v_76)
        v_78 = (v_77 + v_67)
        v_79 = self.to_image(v_78)
        return v_79

def export_torchscript():
    net = Model()
    net.float()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 32, 32, dtype=torch.float)
    v_1 = torch.randint(10, (1, ), dtype=torch.long)

    mod = torch.jit.trace(net, (v_0, v_1))
    mod.save("models/unet_scripted_pnnx.py.pt")

def export_onnx():
    net = Model()
    net.float()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 32, 32, dtype=torch.float)
    v_1 = torch.randint(10, (1, ), dtype=torch.long)

    torch.onnx.export(net, (v_0, v_1), "models/unet_scripted_pnnx.py.onnx", export_params=True, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK, opset_version=13, input_names=['in0', 'in1'], output_names=['out0'])

@torch.no_grad()
def test_inference():
    net = Model()
    net.float()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 32, 32, dtype=torch.float)
    v_1 = torch.randint(10, (1, ), dtype=torch.long)

    return net(v_0, v_1)

if __name__ == "__main__":
    print(test_inference())
